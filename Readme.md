The goal of this assignment is to demonstrate your ability to capture unconventional datasets, clean and store them.

Write a scraper in either python or NodeJS to collect data from Wikipedia about the top cities in the United States. The fields you collect, as well as the volume of data is up to you, but ideally you add additional data beyond the initial table, such as data found on the individual city pages, or other sources of your choice. The final format should be a CSV file that is ready to be uploaded to a BigQuery table.

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"            WEB SCRAPER                                                                                                  "
"The program  extracts the basic data about the top cities in United States based on the population of each cities.       "
"and collects the basic informations each cities such as County,year of Settled,Incorporated,Government Type,Mayor,       "
"City, Land Area, Area covered by Water,Elevation,Time zone, Time zone at Summer,Website,ZIP Codes,Area codes,            "
"population Density.                                                                                                      "
"the output is stored as  Top_cities_in_the_United_States.csv , that is compatible to store as BigQuery table.            "
"The program was developed in Anaconda spyder and python 3.6                                                              "
"                                                                                                                         "
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
